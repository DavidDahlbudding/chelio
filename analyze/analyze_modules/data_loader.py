import numpy as np
from pathlib import Path
import warnings
from typing import Dict, Any, List

# Utility functions for formatting run names, adapted from notebooks
def _format_e_nums(num):
    """Formats a number in scientific notation consistent with run names."""
    num_str = f'{num:.2e}'.replace('0', '').replace('.e', 'e').replace('+', '')
    if num_str.endswith('e'):
        num_str += '0'
    return num_str

def _format_CtoO_float(f):
    """Formats the C/O ratio float consistent with run names."""
    if f == int(f):
        return f"{f:.1f}"
    else:
        return f"{f:.10g}"

def _build_run_name(params: Dict[str, Any]) -> str:
    """
    Constructs the unique run_name string from a dictionary of parameters.
    This must match the directory names generated by the simulation scripts.
    """
    planet = params.get('planet', 'Earth')
    p0 = params['P0']
    tint = params['Tint']
    cpluso = params['CplusO']
    ctoo = params['CtoO']
    nocond = params.get('noCond', False)
    add = params.get('add', '')

    nocond_str = '_NoCond' if nocond else ''
    
    return f"{planet}_P0={_format_e_nums(p0)}_Tint={tint}{nocond_str}_CplusO={_format_e_nums(cpluso)}_CtoO={_format_CtoO_float(ctoo)}{add}"

class ChelioRun:
    """
    Represents a single Chelio simulation run, handling data loading and processing.
    """
    def __init__(self, output_folder_path: str or Path, run_name: str, load_mode: str = 'last'):
        if not isinstance(output_folder_path, Path):
            output_folder_path = Path(output_folder_path)
            
        self.output_folder_path = output_folder_path
        self.run_name = run_name
        self.run_path = self.output_folder_path / self.run_name
        self.load_mode = load_mode

        # Attributes to be populated by read_data()
        self.n_elem = None
        self.n_mol = None
        self.n_dust = None
        self.n_layers = None
        self.atom_names: List[str] = []
        self.mol_names: List[str] = []
        self.dust_names: List[str] = []
        self.num_iterations_read = 0
        self.final_convergence_status = False
        self.escape_time_yrs = np.nan

        # Iteration-specific raw data
        self.pressures_bar: np.ndarray = np.array([])
        self.temperatures_K: np.ndarray = np.array([])
        self.altitudes_cm: np.ndarray = np.array([])
        self.nHtots: np.ndarray = np.array([])
        self.atoms_raw: np.ndarray = np.array([])
        self.mols_raw: np.ndarray = np.array([])
        self.supersats: np.ndarray = np.array([])
        self.dusts_raw: np.ndarray = np.array([])
        self.eps_atoms_raw: np.ndarray = np.array([])
        self.dust_to_gas_raw: np.ndarray = np.array([])
        self.dust_vol: np.ndarray = np.array([])
        self.mus: np.ndarray = np.array([])
        self.convective_flags: np.ndarray = np.array([])

        # Iteration-specific converted data
        self.is_converted = False
        self.atoms_vmr: np.ndarray = np.array([])
        self.mols_vmr: np.ndarray = np.array([])
        self.dusts_vmr: np.ndarray = np.array([])
        self.eps_atoms_mr: np.ndarray = np.array([])
        self.dust_to_gas_mr: np.ndarray = np.array([])
        self.n_tots: np.ndarray = np.array([])

    def read_data(self):
        """
        Reads all data files associated with the run from disk.
        Optimized for 'last' load_mode to save memory.
        """
        i = 0
        last_valid_i = -1
        while True:
            conc_path = self.run_path / f"Static_Conc_{i}.dat"
            if not conc_path.exists():
                break
            last_valid_i = i
            i += 1
        
        if last_valid_i == -1:
            self._populate_with_nan()
            return
            
        if self.load_mode == 'last':
            indices_to_load = [last_valid_i]
        else: # load_mode == 'all'
            indices_to_load = range(last_valid_i + 1)
        
        data_frames = []
        mus_list = []
        altitudes_list = []
        convective_list = []

        # Read header from the first available file to initialize dimensions
        self._read_header_info(self.run_path / f"Static_Conc_0.dat")
        
        for i in indices_to_load:
            conc_path = self.run_path / f"Static_Conc_{i}.dat"
            # We assume file exists from the check above
            with warnings.catch_warnings():
                warnings.simplefilter("error", UserWarning)
                try:
                    d = np.loadtxt(conc_path, skiprows=3)
                    data_frames.append(d)
                    
                    # Load associated files
                    mu_path = self.run_path / f"vertical_mix_{i}.dat"
                    if mu_path.exists():
                        mus_list.append(np.loadtxt(mu_path, skiprows=1, usecols=3))
                    else: # If any file is missing, it's safer to add NaNs
                        mus_list.append(np.full(self.n_layers, np.nan))
                    
                    tp_path = self.run_path / f"{self.run_name}_tp.dat"
                    if tp_path.exists():
                        altitudes_list.append(np.loadtxt(tp_path, skiprows=2, usecols=3))
                        convective_list.append(np.loadtxt(tp_path, skiprows=2, usecols=6))
                    else:
                        altitudes_list.append(np.full(self.n_layers, np.nan))
                        convective_list.append(np.full(self.n_layers, np.nan))

                except (UserWarning, IndexError, ValueError): # Catches malformed files
                    data_frames.append(np.full((self.n_layers, data_frames[0].shape[1]), np.nan))
                    mus_list.append(np.full(self.n_layers, np.nan))
                    altitudes_list.append(np.full(self.n_layers, np.nan))
                    convective_list.append(np.full(self.n_layers, np.nan))

        self.num_iterations_read = len(data_frames)
        if not data_frames:
            self._populate_with_nan()
            return

        self._process_data_frames(data_frames, mus_list, altitudes_list, convective_list)
        self._read_escape_time()
        self._check_convergence(data_frames[-1])
        
        if self.load_mode == 'last' and not self.final_convergence_status:
            self._populate_with_nan()

    def _read_header_info(self, file_path):
        if not file_path.exists():
             self.n_elem, self.n_mol, self.n_dust, self.n_layers = 0,0,0,0
             return
        dimension = np.genfromtxt(file_path, dtype=int, max_rows=1, skip_header=1)
        self.n_elem, self.n_mol, self.n_dust, self.n_layers = dimension
        
        header = np.loadtxt(file_path, skiprows=2, max_rows=1, dtype=str)
        self.atom_names = list(header[3:4+self.n_elem])
        self.mol_names = list(header[4+self.n_elem:4+self.n_elem+self.n_mol])
        raw_dust_names = header[4+self.n_elem+self.n_mol:4+self.n_elem+self.n_mol+self.n_dust]
        self.dust_names = [name[1:] for name in raw_dust_names]

    def _process_data_frames(self, data_frames, mus_list, altitudes_list, convective_list):
        all_data = np.array(data_frames) # (n_iter, n_layers, n_cols)
        
        self.pressures_bar = all_data[:, :, 2] * 1e-6
        self.temperatures_K = all_data[:, :, 0]
        self.nHtots = all_data[:, :, 1]
        self.atoms_raw = all_data[:, :, 3:4+self.n_elem]
        self.mols_raw = all_data[:, :, 4+self.n_elem:4+self.n_elem+self.n_mol]
        self.supersats = all_data[:, :, 4+self.n_elem+self.n_mol:4+self.n_elem+self.n_mol+self.n_dust]
        self.dusts_raw = all_data[:, :, 4+self.n_elem+self.n_mol+self.n_dust:4+self.n_elem+self.n_mol+2*self.n_dust]
        self.eps_atoms_raw = all_data[:, :, 4+self.n_elem+self.n_mol+2*self.n_dust:4+self.n_elem+self.n_mol+2*self.n_dust+self.n_elem]
        self.dust_to_gas_raw = all_data[:, :, 4+self.n_elem+self.n_mol+2*self.n_dust+self.n_elem]
        
        if all_data.shape[2] > 4+self.n_elem+self.n_mol+2*self.n_dust+self.n_elem+1:
             self.dust_vol = all_data[:, :, 4+self.n_elem+self.n_mol+2*self.n_dust+self.n_elem+1]
        else:
            self.dust_vol = np.full((self.num_iterations_read, self.n_layers), np.nan)

        self.mus = np.array(mus_list) if mus_list else np.full((self.num_iterations_read, self.n_layers), np.nan)
        self.altitudes_cm = np.array(altitudes_list) if altitudes_list else np.full((self.num_iterations_read, self.n_layers), np.nan)
        self.convective_flags = np.array(convective_list) if convective_list else np.full((self.num_iterations_read, self.n_layers), np.nan)

    def _populate_with_nan(self):
        # Ensure header is read to get layer count, even for failed runs, if possible
        if self.n_layers is None:
            self._read_header_info(self.run_path / "Static_Conc_0.dat")
        
        shape = (1, self.n_layers if self.n_layers else 1)
        nan_array = np.full(shape, np.nan)
        self.pressures_bar = nan_array
        self.temperatures_K = nan_array
        self.altitudes_cm = nan_array
        self.nHtots = nan_array
        self.dust_to_gas_raw = nan_array
        self.dust_vol = nan_array
        self.mus = nan_array
        self.convective_flags = nan_array

        self.atoms_raw = np.full(shape + (self.n_elem if self.n_elem else 1,), np.nan)
        self.mols_raw = np.full(shape + (self.n_mol if self.n_mol else 1,), np.nan)
        self.supersats = np.full(shape + (self.n_dust if self.n_dust else 1,), np.nan)
        self.dusts_raw = np.full(shape + (self.n_dust if self.n_dust else 1,), np.nan)
        self.eps_atoms_raw = np.full(shape + (self.n_elem if self.n_elem else 1,), np.nan)
        self.final_convergence_status = False


    def _check_convergence(self, last_data_frame):
        # Based on comments and logic from notebooks, a run has not converged if:
        # 1. The final pressure in the top layer is not 1e-1 dyn/cm^2.
        # 2. The temperature profile is a dummy array of all 1.001 K.
        # This logic is more robust than the original notebook code.
        failed_pressure = last_data_frame[-1, 2] != 1e-1
        failed_temperature = np.all(last_data_frame[:, 0] == 1.001)

        if failed_pressure or failed_temperature:
            self.final_convergence_status = False
        else:
            self.final_convergence_status = True

    def _read_escape_time(self):
        escape_file = self.run_path / 'escape.dat'
        if escape_file.exists():
            with open(escape_file, 'r') as f:
                try:
                    last_line = f.readlines()[-1]
                    self.escape_time_yrs = float(last_line.split()[-1])
                except (IndexError, ValueError):
                    self.escape_time_yrs = np.nan
        else:
            self.escape_time_yrs = np.nan

    def convert_to_vmr(self):
        """
        Converts raw logarithmic data to volume/mass mixing ratios.
        """
        if self.is_converted or self.atoms_raw.size == 0 or np.all(np.isnan(self.atoms_raw)):
            return

        # Calculate n_tots (total number density)
        self.n_tots = np.sum(10**self.mols_raw, axis=-1) + np.sum(10**self.atoms_raw, axis=-1)
        self.n_tots = self.n_tots[..., np.newaxis]

        # Convert atomic abundances (log(cm^-3)) to volume mixing ratios
        self.atoms_vmr = 10**self.atoms_raw / self.n_tots
        
        # Convert molecular abundances (log(cm^-3)) to volume mixing ratios
        self.mols_vmr = 10**self.mols_raw / self.n_tots

        # Convert dust concentrations from log10(nCond/nHtot) to volume mixing ratios
        self.dusts_vmr = 10**self.dusts_raw * self.nHtots[..., np.newaxis] / self.n_tots

        # Convert elemental abundances
        self.eps_atoms_mr = 10**self.eps_atoms_raw
        self.eps_atoms_mr /= np.sum(self.eps_atoms_mr, axis=-1, keepdims=True)

        # Convert dust-to-gas ratio
        self.dust_to_gas_mr = 10**self.dust_to_gas_raw
        
        self.is_converted = True

    def get_iteration_data(self, iteration_index: int = -1) -> Dict[str, Any]:
        """
        Returns a dictionary of all processed data for a specific iteration.
        """
        if not self.is_converted:
            self.convert_to_vmr()

        if self.num_iterations_read == 0:
            return { "error": "No data loaded." }
            
        try:
            # Slicing with ... to handle both 'all' and 'last' modes gracefully
            idx = (Ellipsis, iteration_index) if self.load_mode == 'all' else (Ellipsis,)
            
            data = {
                "pressure_bar": self.pressures_bar[iteration_index],
                "temperature_K": self.temperatures_K[iteration_index],
                "altitude_cm": self.altitudes_cm[iteration_index],
                "nHtot": self.nHtots[iteration_index],
                "mu": self.mus[iteration_index],
                "convective_flag": self.convective_flags[iteration_index],
                "atom_names": self.atom_names,
                "mol_names": self.mol_names,
                "dust_names": self.dust_names,
                "atoms_vmr": self.atoms_vmr[iteration_index],
                "mols_vmr": self.mols_vmr[iteration_index],
                "dusts_vmr": self.dusts_vmr[iteration_index],
                "supersats": self.supersats[iteration_index],
                "eps_atoms_mr": self.eps_atoms_mr[iteration_index],
                "dust_to_gas_mr": self.dust_to_gas_mr[iteration_index],
                "dust_vol": self.dust_vol[iteration_index],
            }
            return data
        except IndexError:
            return { "error": f"Iteration {iteration_index} out of bounds." }

def load_parameter_sweep(
    base_folder: str or Path, 
    fixed_params: Dict[str, Any], 
    varying_param_name: str, 
    varying_param_values: List[Any], 
    load_mode: str = 'last', 
    **kwargs
) -> List[ChelioRun]:
    """
    Loads a series of ChelioRun objects for a parameter sweep.
    """
    if not isinstance(base_folder, Path):
        base_folder = Path(base_folder)
        
    runs = []
    for value in varying_param_values:
        current_params = fixed_params.copy()
        current_params[varying_param_name] = value
        current_params.update(kwargs)
        
        run_name = _build_run_name(current_params)
        run = ChelioRun(base_folder, run_name, load_mode=load_mode)
        run.read_data()
        runs.append(run)
    return runs

def load_parameter_matrix(
    base_folder: str or Path, 
    fixed_params: Dict[str, Any], 
    param1_name: str, 
    param1_values: List[Any], 
    param2_name: str, 
    param2_values: List[Any], 
    what_to_extract: str,
    load_mode: str = 'last',
    mol_type: str = 'mol',
    **kwargs
) -> np.ndarray:
    """
    Loads a 2D matrix of data from a parameter grid. 
    Can extract scalars (e.g., 'T_surf') or 1D profiles (e.g., 'temperatures_K').
    """
    if not isinstance(base_folder, Path):
        base_folder = Path(base_folder)

    mol = mol_type == 'mol'

    dust = mol_type == 'dust'
    supersat = mol_type == 'supersat'
    dust = dust or supersat
    
    atom = mol_type == 'atom'
    eps = mol_type == 'eps'
    atom = atom or eps
    
    # --- Determine the shape of the output array ---
    result_matrix = None
    first_run_processed = False

    for i, p1_val in enumerate(param1_values):
        for j, p2_val in enumerate(param2_values):
            current_params = fixed_params.copy()
            current_params[param1_name] = p1_val
            current_params[param2_name] = p2_val
            current_params.update(kwargs)

            run_name = _build_run_name(current_params)
            run = ChelioRun(base_folder, run_name, load_mode=load_mode)
            run.read_data()
            run.convert_to_vmr()
            
            # --- Extract Data ---
            data_point = np.nan
            if run.final_convergence_status:
                
                if hasattr(run, what_to_extract):
                    data_point = np.squeeze(getattr(run, what_to_extract))
                elif what_to_extract in run.mol_names and mol:
                    idx = run.mol_names.index(what_to_extract)
                    data_point = run.mols_vmr[0, :, idx]
                elif what_to_extract in run.dust_names and dust:
                    idx = run.dust_names.index(what_to_extract)
                    if supersat:
                        data_point = run.supersats[0, :, idx]
                    else:
                        data_point = run.dusts_vmr[0, :, idx]
                elif what_to_extract in run.atom_names and atom:
                    idx = run.atom_names.index(what_to_extract)
                    if eps:
                        idx = idx - 1 # remove electron (first entry of atom_names)
                        data_point = run.eps_atoms_mr[0, :, idx]
                    else:
                        data_point = run.atoms_vmr[0, :, idx]
                # --- Handle special scalar cases for convenience ---
                elif what_to_extract == 'T_surf' or what_to_extract == 'T_BOA':
                    data_point = run.temperatures_K[0, 0]
                elif what_to_extract == 'T_TOA':
                    data_point = run.temperatures_K[0, -1]

            # --- Initialize result matrix on first valid data point ---
            if not first_run_processed:
                if hasattr(data_point, 'shape'):
                    # It's a profile
                    profile_shape = data_point.shape
                    result_matrix = np.full((len(param1_values), len(param2_values)) + profile_shape, np.nan)
                else:
                    # It's a scalar
                    result_matrix = np.full((len(param1_values), len(param2_values)), np.nan)
                first_run_processed = True
            
            if result_matrix is not None:
                result_matrix[i, j] = data_point
    
    if result_matrix is None:
        # This happens if no runs were found or converged
        return np.array([])

    return result_matrix 